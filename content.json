{"pages":[{"title":"About 1인분 하고픈 DS","text":"늦은 나이에 데이터 분석이라는 직군을 알게되어 별 볼일 없는 모든 커리어를 접어둔채 데이터 탐색을 시작했습니다. 블로그를 통해 여러 사람들과 소통하고 싶고 여러 사람들에게 도움을 주고 싶습니다. 꾸준히 10년 이상 블로그 활동하려 합니다. 사람답게 1인분을 하고자 노력하고 있습니다. 혹시나 필요하실 수도 있어서 남깁니다. MacBook Pro (16-inch, 2019) 프로세서 : 2.3 GHz 8코어 Intel Core i9 메모리 : 16GB 2667 MHz DDR4 그래픽 : Intel UHD Graphics 630 1536 MB 블로그에 실린 모든 내용은 출처가 있는 내용을 저의 지극히 주관적인 관점으로 재해석해 올린 내용들입니다. 게시글 내용에 수정이 필요하거나 게시글이 불편하여 내리길 원하시면 아래 e-mail로 보내주시면 검토하여 진행하도록 하겠습니다. 감사합니다. About 페이지를 만드는데 도움주신 분께 감사드립니다. 출처 : https://kinetic27.github.io/2020/03/06/build-blog-with-hexo-github/#About-%ED%8E%98%EC%9D%B4%EC%A7%80","link":"/about/index.html"},{"title":"all-archives","text":"","link":"/all-archives/index.html"},{"title":"all-tags","text":"","link":"/all-tags/index.html"},{"title":"all-categories","text":"","link":"/all-categories/index.html"}],"posts":[{"title":"Hexo 블로그 만들기","text":"안녕하세요!hexo 블로그 만드는 방법입니다. hexo 블로그 생성전 아래 2가지를 먼저 설치해야 합니다. Node.js(https://nodejs.org/en/) Should be at least Node.js 8.10, recommends 10.0 or higher Git(https://git-scm.com/) github에서 repository를 생성해야 합니다. 참고: https://greeksharifa.github.io/github/2018/06/29/github-usage-02-create-project/ hexo 블로그 공식 홈페이지https://hexo.io/ko/index.html hexo 블로그 설치하기 공식문서https://hexo.io/ko/docs/ 터미널을 엽니다. 블로그를 만들면 폴더가 생성됩니다. 폴더를 생성하고자 하는 곳으로 가셔서 아래의 $를 제외한 명령어를 입력하세요. 띄어쓰기 대소문자 모두 그대로 입력해주세요.121. $ npm install hexo-cli -g2. $ hexo init blog 블로그를 만든 폴더로 이동합니다. 1235. $ cd blog6. $ npm install7. $ hexo server 로컬에서 hexo 블로그를 확인하실 수 있습니다. 아래 터미널의 경로로 가셔서 파일을 만듭니다. 터미널에서의 경로본인이 만든 폴더 안의 source 폴더 안에 _post 1$ source/_posts/ 파일 이름(본인이 원하는 이름을 적으시면 됩니다.)파일명.md 파일 안에 원하는 내용을 적는데, 맨 위에 제목은 아래처럼 작성하셔야 합니다. 현재 제가 알고 있는 바로는 그렇습니다. 12345678---title: Hexo에 글을 쓰고 사이트에 반영하기---위처럼 제목을 적으셨으면 아래줄에 내용을 입력하면 됩니다. 1번 내용2번 내용 등주석을 적을 때는 `###`을 사용하여 적으시면 됩니다. 올릴 내용이 준비되었다면 아래와 같이 4가지 단계를 거쳐 블로그에 내용을 올리시면 됩니다. 1번: 헥소에 변화를 주겠다고 얘기한다.2번: 헥소에 내용을 반영하겠다고 얘기한다.3번: 헥소에 반영된 내용을 확인하겠다고 얘기한다. 수정이 필요하면 수정을 진행한다. 수정이 완료되면 아래 4번을 통해 내용을 공개하겠다고 얘기한다.4번: 블로그에 내용을 게시하겠다고 얘기한다. 터미널 창으로 가셔서 $ 표시 뒤의 글자를 치세요.1. $ hexo clean2. $ hexo generate3. $ hexo server # 생략가능4. $ hexo deploy추가적인 내용은 지속적으로 편집하도록 하겠습니다.최대한 자세히 쓰려고 노력중입니다.여러가지 의견 감사히 받겠습니다.댓글을 어떻게 활성화해야 하는지 몰라 여기저기 구글링중입니다.","link":"/2020/04/05/Hexo%20create/"},{"title":"EDA","text":"탐색적 데이터 분석EDA(Exploratory Data Analysis)들어가기 전에 바쁘시거나 요점만 알고싶으신 분들을 위해 정리 해봤습니다. 데이터 분석의 목적을 정한다. EDA를 위해 데이터를 분행하여 확인한다. 객관적인 도메인 지식을 참고한다. 보통 제가 듣기로는 데이터를 요리의 재료로 흔히들 비교 합니다.김치란 재료를 어떻게 사용하느냐에 따라 김치전도 될 수 있고, 김치찌개도 될 수 있으며, 김치 볶음밥도 될 수 있듯이 말이죠. 데이터도 분석가가 어떤 알고리즘을 사용하여 분석하느냐에 따라 결과가 달라질 수 있기 때문이라고 생각합니다. 그럼 탐색적 데이터 분석은 어떻게 해야 하는 것일까요? 먼저, EDA를 하기전 해야 할 것이 있습니다. 바로, 어떤 요리를 만들지 정하는 것입니다. 즉, 목적을 정하는 것입니다. 예측, 추천, 분석 등을 정해야 합니다. 삼천포로 빠질 수 있기 때문입니다. 삼천포는 우선 하던 일을 마무리 한 후에 하시면 정신건강에 도움이 될 거라 확신합니다. 데이터 분석의 목적과 목표가 정해졌다면, 가지고 있는 데이터 혹은 가져올 전처리되지 않은 데이터를 어떻게 활용하여 원하는 목표를 달성할 것인지 데이터를 알아봐야겠죠? 개인적으로는 객관적이고 정량적(定量的)으로 증명할 수 있는 도메인 지식을 가지고 있으면 분석하는데 유용하게 사용될 것 같습니다. 분석에 도움이 안될 것 같은 데이터들은 제외시키고, null 값(정보가 없는 데이터)은 어떻게 처리 할지도 생각해 봐야 합니다. 또 다시 요리에 비교를 해보면, 재료가 될 김치에 어떤 액젓이 들어갔는지, 고추가루는 국산인지, 고추가루의 크기는 어느 정도인지, 색깔은 밝은지 어두운지 등등 낱낱히 파헤치는 작업이 EDA 작업이라고 생각하시면 될 것 같습니다.","link":"/2020/04/08/EDA/"},{"title":"Agile","text":"바쁘신 분을 위한 Agile(애자일) 방법론 3줄 요약출처 : https://m.post.naver.com/viewer/postView.nhn?volumeNo=18903174&amp;memberNo=36647560 작업 계획을 짧은 단위로 세우고 시제품을 만들어 나가는 사이클을 반복 고객의 요구 변화에 유연하고도 신속하게 대응하는 개발 방법론 요즘 에자일, 에자일 기법에 대해 2번 이상 듣기도 하고 기업에서도 에자일 기법으로 프로세스를 진행한다고 하니 무엇인지에 대한 개념도 알아보고 내 삶에 적용 시키기도 해볼 겸해서 간단하게 기록하려합니다. 우선, 애자일 방법이란 ?기업경영 및 소프트웨어 등의 개발을 고객중심으로 진행하는 방법론 애자일방식의 조직운영 고객중심 아웃풋 중심 유연하고도 민첩한 대응력 자율성과 권한을 가진 조직 운영 에자일 개발 선언문 http://agilemanifesto.org/ 애자일 방법은 급변화하고 진화하고 있는 환경에 효과적으로 대응할 수 있는 방법이라고 생각됩니다. 피드백 댓글로 남겨주세요~!감사합니다 :)","link":"/2020/04/08/Agile/"},{"title":"Hexo_deploy_contents","text":"※ 저처럼 시작한지 얼마 되지 않으신 분들은 Visual Studio Code를 다운받아 시작하시는 것을 추천드립니다. 헥소 블로그를 강사님의 도움으로 만들어 놓고 이제야 시작을 합니다.그래서 여기에 쓰면 글이 반영되는지 확인중입니다.그리고 여기에 글을 쓰면 반영되는지 확인했습니다. 그럼, 내가 쓴 글이 블로그에 어떻게 올라가는지 제가 아는 내용을 최대한 자세히 설명 드리겠습니다 :) hexo 블로그 만들기 우선 터미널을 실행합니다. 아래의 경로로 가셔서 파일을 만듭니다. 터미널에서의 경로본인이 만든 폴더 안의 source 폴더 안에 _post 1$ source/_posts/ 파일 이름(본인이 원하는 이름을 적으시면 됩니다.)파일명.md 파일 안에 원하는 내용을 적는데, 맨 위에 제목은 아래처럼 작성하셔야 합니다. 현재 제가 알고 있는 바로는 그렇습니다. 12345678---title: Hexo에 글을 쓰고 사이트에 반영하기---위처럼 제목을 적으셨으면 아래줄에 내용을 입력하면 됩니다. 1번 내용2번 내용 등주석을 적을 때는 `###`을 사용하여 적으시면 됩니다. 올릴 내용이 준비되었다면 아래와 같이 4가지 단계를 거쳐 블로그에 내용을 올리시면 됩니다. 1번: 헥소에 변화를 주겠다고 얘기한다.2번: 헥소에 내용을 반영하겠다고 얘기한다.3번: 헥소에 반영된 내용을 확인하겠다고 얘기한다. 수정이 필요하면 수정을 진행한다. 수정이 완료되면 아래 4번을 통해 내용을 공개하겠다고 얘기한다.4번: 블로그에 내용을 게시하겠다고 얘기한다. 터미널 창으로 가셔서 $ 표시 다음을 따라 치세요.1. $ hexo clean2. $ hexo generate3. $ hexo server4. $ hexo deploy추가적인 내용은 지속적으로 편집하도록 하겠습니다.최대한 자세히 쓰려고 노력중입니다.여러가지 의견 감사히 받겠습니다.댓글을 어떻게 활성화해야 하는지 몰라 여기저기 구글링중입니다.","link":"/2020/04/03/Hexo-deploy-contents/"},{"title":"STAR","text":"자기소개 STAR 기법 S T A R 추후 작성 예정입니다.","link":"/2020/04/09/STAR/"},{"title":"판다스(pandas) cheet sheet","text":"출처: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf 판다스 치트시트 : 판다스 활용시 발암 예방을 위한 엑기스 모음집","link":"/2020/04/03/Pandas/"},{"title":"machine_learning","text":"머신러닝 요약 기계가 주어진 데이터틀 통해 규칙을 찾는 것 데이터를 기계에게 주고 규칙을 찾는 것","link":"/2020/04/14/Machine_Learning/"},{"title":"Linear Regression","text":"선형회귀분석 순서 주제 선정하기 개인적으로 가장 중요하다고 생각되는 부분입니다. 자료가 있는 상황이라면 자료를 하나씩 정리하는 것도 필요하다고 생각합니다. 데이터 수집 주제를 선정하였다면 예측하고 싶은 내용 혹은 결과에 대해 영향을 미치고 필요하다고 생각되는 데이터를 모아야 합니다. 데이터를 수집하는 방법은 설문조사, 크롤링 등이 있으며, 데이터가 제한된 상황이 있을 수 있습니다. (즉, 주어진 데이터로만 분석해야 하는 상황) EDA 진행하기 수집한 데이터를 회귀분석 목적에 맞게 전처리합니다. 실수형 독립변수, 카테고리형 독립변수에 대해 어떻게 처리할지 염두하여 진행해야 합니다. 추후 업데이트 진행예정","link":"/2020/04/08/Linear_Regression/"},{"title":"cross_validation","text":"anovastatsmodels 사이트 : https://www.statsmodels.org/stable/examples/notebooks/generated/interactions_anova.html python에서 anova library 불러옵니다.1from statsmodels.stats.anova import anova_lm 수식 예제$ax^2+bx+c&gt;0$ 추후 작성예정입니다.","link":"/2020/04/09/cross-validation/"},{"title":"favicon","text":"favicon 출처: 동물 png from pngtree.com","link":"/2020/04/25/favicon/"},{"title":"data analysis","text":"데이터 분석에 대하여 알아보겠습니다.","link":"/2020/04/08/data_analysis/"},{"title":"git","text":"git에 대해 작성할 예정입니다.","link":"/2020/04/15/git/"},{"title":"hadoop","text":"오늘은 하둡에 대해 알아보겠습니다.","link":"/2020/04/15/hadoop/"},{"title":"안녕하세요 !!","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/04/02/hello-world/"},{"title":"porject","text":"EDA project아파트 가격분석 EDA 업데이트 예정","link":"/2020/04/23/porject/"},{"title":"spark","text":"패스트캠퍼스에서 spark에 대해서 배우고 있고, 배웠는데도 배운 내용에 대해 이해가 되지 않는 나의 무지함에 분노하면서 스파크에 대해 정리하고자 합니다.조언은 언제나 환영합니다. 블로그 댓글 기능을 언제 활성화 할 수 있을지는 현재까지 잘 모르겠습니다.우선 환경설정에 대해 알아보겠습니다.개념을 잡으려 노력중입니다.","link":"/2020/04/07/spark/"},{"title":"seo","text":"website seo 하기출처 : https://msj0319.github.io/2020/02/14/Hexo-Blog-%EA%B5%AC%EA%B8%80-%EC%82%AC%EC%9D%B4%ED%8A%B8-%EB%93%B1%EB%A1%9D-%EB%B0%8F-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84-%EC%B5%9C%EC%A0%81%ED%99%94-SEO/#more","link":"/2020/04/17/seo/"},{"title":"re(regular expression)","text":"정규표현식 regular expression 특정한 패턴과 일치하는 문자열를 ‘검색’, ‘치환’, ‘제거’ 하는 기능을 지원 정규표현식의 도움없이 패턴을 찾는 작업(Rule 기반)은 불완전 하거나, 작업의 cost가 높음 e.g) 이메일 형식 판별, 전화번호 형식 판별, 숫자로만 이루어진 문자열 등 raw string 문자열 앞에 r이 붙으면 해당 문자열이 구성된 그대로 문자열로 변환 12345a = 'abcdef\\n' # escapce 문자열print(a)b = r'abcdef\\n'print(b) 기본 패턴 a, X, 9 등등 문자 하나하나의 character들은 정확히 해당 문자와 일치 e.g) 패턴 test는 test 문자열과 일치 대소문자의 경우 기본적으로 구별하나, 구별하지 않도록 설정 가능 몇몇 문자들에 대해서는 예외가 존재하는데, 이들은 틀별한 의미로 사용 됨 . ^ $ * + ? { } [ ] \\ | ( ) . (마침표) - 어떤 한개의 character와 일치 (newline(엔터) 제외) \\w - 문자 character와 일치 [a-zA-Z0-9_] \\s - 공백문자와 일치 \\t, \\n, \\r - tab, newline, return \\d - 숫자 character와 일치 [0-9] ^ = 시작, $ = 끝 각각 문자열의 시작과 끝을 의미 \\가 붙으면 스페셜한 의미가 없어짐. 예를들어 \\.는 .자체를 의미 \\\\는 \\를 의미 자세한 내용은 링크 참조 https://docs.python.org/3/library/re.html search method 첫번째로 패턴을 찾으면 match 객체를 반환 패턴을 찾지 못하면 None 반환 12345678910import rem = re.search(r'abc', '123abdef')mm = re.search(r'\\d\\d\\d\\w', '112abcdef119')mm = re.search(r'..\\w\\w', '@#$%ABCDabcd')m metacharacters (메타 캐릭터)[] 문자들의 범위를 나타내기 위해 사용 [] 내부의 메타 캐릭터는 캐릭터 자체를 나타냄 e.g) [abck] : a or b or c or k [abc.^] : a or b or c or . or ^ [a-d] : -와 함께 사용되면 해당 문자 사이의 범위에 속하는 문자 중 하나 [0-9] : 모든 숫자 [a-z] : 모든 소문자 [A-Z] : 모든 대문자 [a-zA-Z0-9] : 모든 알파벳 문자 및 숫자 [^0-9] : ^가 맨 앞에 사용 되는 경우 해당 문자 패턴이 아닌 것과 매칭 1234567re.search(r'[cbm]at', 'aat')re.search(r'[0-4]haha', '7hahah')re.search(r'[abc.^]aron', 'daron')re.search(r'[^abc]aron', '0aron') \\ 다른 문자와 함께 사용되어 특수한 의미를 지님 \\d : 숫자를 [0-9]와 동일 \\D : 숫자가 아닌 문자 [^0-9]와 동일 \\s : 공백 문자(띄어쓰기, 탭, 엔터 등) \\S : 공백이 아닌 문자 \\w : 알파벳대소문자, 숫자 [0-9a-zA-Z]와 동일 \\W : non alpha-numeric 문자 [^0-9a-zA-Z]와 동일 메타 캐릭터가 캐릭터 자체를 표현하도록 할 경우 사용 \\. , \\\\ 123re.search(r'\\Sand', 'apple land banana')re.search(r'\\.and', '.and') . 모든 문자를 의미 1re.search(r'p.g', 'pig') 반복패턴 패턴 뒤에 위치하는 *, +, ?는 해당 패턴이 반복적으로 존재하는지 검사 ‘+’ -&gt; 1번 이상의 패턴이 발생 ‘*’ -&gt; 0번 이상의 패턴이 발생 ‘?’ -&gt; 0 혹은 1번의 패턴이 발생 반복을 패턴의 경우 greedy하게 검색 함, 즉 가능한 많은 부분이 매칭되도록 함 e.g) a[bcd]*b 패턴을 abcbdccb에서 검색하는 경우 ab, abcb, abcbdccb 전부 가능 하지만 최대한 많은 부분이 매칭된 abcbdccb가 검색된 패턴 1234567891011re.search(r'a[bcd]*b', 'abcbdccb')re.search(r'b\\w+a', 'banana')re.search(r'i+', 'piigiii')re.search(r'pi+g', 'pg')re.search(r'pi*g', 'pg')re.search(r'https?', 'http://www.naver.com') ^, $ ^ 문자열의 맨 앞부터 일치하는 경우 검색 $ 문자열의 맨 뒤부터 일치하는 경우 검색 123456789re.search(r'b\\w+a', 'cabana')re.search(r'^b\\w+a', 'cabana')re.search(r'^b\\w+a', 'babana')re.search(r'b\\w+a$', 'cabana')re.search(r'b\\w+a$', 'cabanap') grouping ()을 사용하여 그루핑 매칭 결과를 각 그룹별로 분리 가능 패턴 명시 할 때, 각 그룹을 괄호() 안에 넣어 분리하여 사용 1234m = re.search(r'(\\w+)@(.+)', 'test@gmail.com')print(m.group(1))print(m.group(2))print(m.group(0)) {} *, +, ?을 사용하여 반복적인 패턴을 찾는 것이 가능하나, 반복의 횟수 제한은 불가 패턴뒤에 위치하는 중괄호{}에 숫자를 명시하면 해당 숫자 만큼의 반복인 경우에만 매칭 {4} - 4번 반복 {3,4} - 3 ~ 4번 반복 1re.search('pi{3,5}g', 'piiiiig') 미니멈 매칭(non-greedy way) 기본적으로 *, +, ?를 사용하면 greedy(맥시멈 매칭)하게 동작함 *?, +?을 이용하여 해당 기능을 구현 123re.search(r'&lt;.+&gt;', '&lt;html&gt;haha&lt;/html&gt;')re.search(r'&lt;.+?&gt;', '&lt;html&gt;haha&lt;/html&gt;') {}? {m,n}의 경우 m번 에서 n번 반복하나 greedy하게 동작 {m,n}?로 사용하면 non-greedy하게 동작. 즉, 최소 m번만 매칭하면 만족 123re.search(r'a{3,5}', 'aaaaa')re.search(r'a{3,5}?', 'aaaaa') match search와 유사하나, 주어진 문자열의 시작부터 비교하여 패턴이 있는지 확인 시작부터 해당 패턴이 존재하지 않다면 None 반환 12345re.match(r'\\d\\d\\d', 'my number is 123')re.match(r'\\d\\d\\d', '123 is my number')re.search(r'^\\d\\d\\d', '123 is my number') findall search가 최초로 매칭되는 패턴만 반환한다면, findall은 매칭되는 전체의 패턴을 반환 매칭되는 모든 결과를 리스트 형태로 반환 1re.findall(r'[\\w-]+@[\\w.]+', 'test@gmail.com haha test2@gmail.com nice test test') sub 주어진 문자열에서 일치하는 모든 패턴을 replace 그 결과를 문자열로 다시 반환함 두번째 인자는 특정 문자열이 될 수도 있고, 함수가 될 수 도 있음 count가 0인 경우는 전체를, 1이상이면 해당 숫자만큼 치환 됨 1re.sub(r'[\\w-]+@[\\w.]+', 'great', 'test@gmail.com haha test2@gmail.com nice test test', count=1) compile 동일한 정규표현식을 매번 다시 쓰기 번거로움을 해결 compile로 해당표현식을 re.RegexObject 객체로 저장하여 사용가능 123email_reg = re.compile(r'[\\w-]+@[\\w.]+')email_reg.search('test@gmail.com haha good')email_reg.findall() 연습문제 아래 뉴스에서 이메일 주소를 추출해 보세요 다음중 올바른 (http, https) 웹페이지만 찾으시오 1234567891011121314151617181920212223242526272829303132333435import requestsfrom bs4 import BeautifulSoup# 위의 두 모듈이 없는 경우에는 pip install requests bs4 실행def get_news_content(url): response = requests.get(url) content = response.text soup = BeautifulSoup(content, 'html5lib') div = soup.find('div', attrs = {'id' : 'harmonyContainer'}) content = '' for paragraph in div.find_all('p'): content += paragraph.get_text() return contentnews1 = get_news_content('https://news.v.daum.net/v/20190617073049838')print(news1)email_reg = re.compile(r'[\\w-]+@[\\w.]+\\w+')email_reg.search(news1)webs = ['http://www.test.co.kr', 'https://www.test1.com', 'http://www.test.com', 'ftp://www.test.com', 'http:://www.test.com', 'htp://www.test.com', 'http://www.google.com', 'https://www.homepage.com.']web_reg = re.compile(r'https?://[\\w.]+\\w+$')list(map(lambda w:web_reg.search(w) != None, webs))","link":"/2020/04/24/re/"},{"title":"python","text":"파이썬 마크다운 문법 사용법 3줄 요약 python is really cool python pandas depth1 depth2 numpy java c++ golang python java c++ 파이썬은 재밌다. y = 3x $y = 3x$ 12a = 10print(a) 12a = 10print(a) https://www.python.org/ 파이썬 공식 페이지","link":"/2020/04/05/python-0/"},{"title":"terminal_basic_command","text":"Mac Terminal basic command zsh : 2020 mac 기본 터미널 iTrem : 현재 사용하고 있는 터미널 oh my zsh : 터미널 설정 오픈소스출처 : https://github.com/ohmyzsh/ohmyzsh 현재위치 파악 및 폴더 이동하기12345678$ pwd $ ll$ ls -al$ ls$ cd Documents$ cd ..$ cd Music/Music$ cd ~ pwd : 현재 위치의 절대 경로 ll : 폴더 ls -al : 폴더 상세내용 표시 ls : cd Documents : cd .. : cd Music/Music : cd ~ : 폴더, 파일 생성 및 삭제 명령어참고사항 : 15번 $ 표시가 없는 esc는 esc를 입력하라는 것이 아닌 esc키를 누르라는 의미입니다.12345678910111213$ mkdir test$ cd test$ touch test$ vi test $ i$ :set nu$ test esc$ :wq$ rm test$ ll$ cd ..$ rmdir test mkdir test : cd test : touch test : vi test : i : 터미널 창 왼쪽 아래 - - INSERT - - 라고 보이며, vi editor 내부에 글자를 적을 수 있습니다. :set nu : 에디터 내부에 라인이 설정됩니다. test : 테스트라고 작성해봅시다! 혹은 아무글자나 작성해봅시다. esc키를 누르면 왼쪽 아래 - - INSERT - - 가 사라집니다. wq : 작성한 내용을 저장 후 빠져나옵니다. rm test : test 파일을 삭제합니다. ll : 폴더 내부에 있는 내용물을 보여줍니다. cd .. : 상위 폴더로 이동합니다. rmdir test : test 폴더를 삭제합니다. 12$ ls$ ll ls : 현재 경로에 있는 폴더, 파일을 보여줍니다. ll : 현재 경로에 있는 폴더, 파일을 보여줍니다. 단, ls보다 상세하게 보여줍니다. (권한, 사용자계정 등) 추가 업데이트 예정입니다.오탈자 및 조언 댓글로 남겨주세요.감사합니다 :)","link":"/2020/04/15/terminal-basic-command/"},{"title":"test.html","text":"BeautifulSoup test Contents Title Test contents 추후 작성할 포스트 1. python os 2.","link":"/2020/04/21/test-html/"},{"title":"test","text":"테스트 페이지입니다.why dosen’t work disqus?","link":"/2020/04/14/test/"},{"title":"sql","text":"","link":"/2020/04/08/sql/"},{"title":"visited_count","text":"블로그 방문자 수 설정하기참조 : https://msj0319.github.io/2020/02/15/Hexo-Blog-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EB%B0%A9%EB%AC%B8%EC%9E%90-%EB%B0%8F-%EC%A1%B0%ED%9A%8C%EC%88%98-%EC%B9%B4%EC%9A%B4%ED%8C%85-%EA%B8%B0%EB%8A%A5-%EB%84%A3%EA%B8%B0/","link":"/2020/04/17/visited-count/"},{"title":"webcrawling","text":"1. 개발자 도구를 활용한 웹페이지 분석 chrome 기준 웹 브라우저 : html로 작성된 내용을 user(사람들)가 보기 쉽게 랜더링 해주는 기능을 함 Elements 탭 원하는 데이터로 이동하는 기능을 사용 엘레먼트 탭 : 왼쪽 상단에 있음, 원하는 데이터를 클릭했을 때 어떤 테그와 어떤 속성을 가지는지 표시해주는 역할을 함 어떤 태그와 속성을 가지는지 먼저 파악해야 함 Network 탭 Preserve log : 체크 시, 로그가 지워지지 않고 유지됨 브라우저가 서버에 요청되는 모든 요청을 로그함 url 확인 가능 요청이 많은 이유 : 이미지 등은 첫번째 요청에 한번에 오지 않고, 따로 요청하여 받아옴 처음엔 기본적인 데이터만 넘기고, 나머지 데이터는 브라우저에서 ajax 등의 기술을 이용해서 비동기적으로 가져갈 수 있도록 함 HTTP(Hyper Text Transfer Protocol) : HTML 문서 등의 리소스를 전송하는 프로토콜(규약) 클라이언트(user가 사용하는 브라우저)가 서버에 HTTP 요청(Get, Post 등) 서버에서 클라이언트로 HTTP 응답을 함 Get 요청 : 데이터를 url에 포함하여 전달(주로 리소스 요청에 사용), 정보의 공유가능 Post 요청 : 데이터를 Form data에 포함하여 전달(주로 로그인에 사용) rendering(렌더링) : html을 받아 사용자(사람들)이 볼 수 있도록 출력해주는 작업","link":"/2020/04/03/webcrawling-1/"},{"title":"webcrawling","text":"python의 request 모듈을 사용하여 http request/resopnse 확인하기requests 모듈 http request/response를 위한 모듈 HTTP method를 메소드 명으로 사용하여 request 요청 예) get, post 123456789101112131415import requests# get 방식url = 'https://news.v.daum.net/v/20190728165812603'resp = requests.get(url)resp.text# post 방식url = 'https://www.kangcom.com/member/member_check.asp'data = { 'id': 'testid', 'pwd': 'password'}resp = requests.post(url, data=data)resp.text HTTP header 데이터 이용하기 header 데이터 구성하기 header 데이터 전달하기 1234567url = 'https://news.v.daum.net/v/20190728165812603'headers = { 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36'}resp = requests.get(url, headers=headers)resp.text HTTP response 처리하기 response 객체의 이해 status_code 확인하기 text 속성 확인하기 123456url = 'https://news.v.daum.net/v/20190728165812603'resp = requests.get(url)if resp.status_code == 200: resp.headerselse: print('error') BeautifulSoup의 find와 find_all 함수 find 함수 조건에 만족하는 하나의 tag만 검색 특정 html tag를 검색 검색 조건을 명시하여 찾고자하는 tag를 검색 12345678tag = soup.find('h3')tag.get_text()tag = soup.find('p')tag.get_text()tag = soup.find('div', id='upper')tag.get_text().strip() find_all함수 조건에 맞는 모든 tag를 리스트로 반환합니다. get_text 함수 tag안의 value를 추출 부모tag의 경우, 모든 자식 tag의 value를 추출 attribute 값 추출하기 경우에 따라 추출하고자 하는 값이 attribute에도 존재함 이 경우에는 검색한 tag에 attribute 이름을 [ ]연산을 통해 추출가능 예) div.find(‘h3’)[‘title’] 12tag = soup.find('h3')tag['title'] CSS의 select_one과 select 함수 CSS를 이용하여 tag 찾기 select, select_one함수 사용 css selector 사용법 태그명 찾기 tag 자손 태그 찾기 - 자손 관계 (tag tag) 자식 태그 찾기 - 다이렉트 자식 관계 (tag &gt; tag) 아이디 찾기 #id 클래스 찾기 .class 속성값 찾기 [name=’test’] 속성값 prefix 찾기 [name ^=’test’] 속성값 suffix 찾기 [name $=’test’] 속성값 substring 찾기 [name *=’test] n번째 자식 tag 찾기 :nth-child(n)","link":"/2020/04/21/webcrawling-3/"},{"title":"webcrawling","text":"web crawling 하기전에 알아둬야 할 사항 예를들어, 네이버 홈페이지를 크롤링한다고 하면 www.naver.com/robots.txt을 브라우저 주소창에 입력하면 로봇 배제 규약에 관한 내용이 나옵니다. robots.txt 내용 요약 모든 로봇 접근 허락User-agent: *Allow : / 모든 로봇 접근 차단User-agent: *Disallow: / 모든 로봇에 디렉토리 3곳 접근 차단User-agent: *Disallow: /cgi-bin/Disallow: /tmp/Disallow: /junk/ 모든 로봇에 특정 파일 접근 차단User-agent: *Disallow: /directory/file.html BadBot 로봇에 모든 파일 접근 차단User-agent: BadBotDisallow: / BadBot과 Googlebot에 특정 디렉토리 접근 차단User-agent: BadBotUser-agent: GooglebotDisallow: /private/ 참고사항 2020년 4월 21일 현재 네이버 로봇 규약 설정출처: https://searchadvisor.naver.com/guide/seo-basic-robots 사이트의 루트 페이지만 수집 허용으로 설정합니다.User-agent: *Disallow: /Allow: /$ sitemap.xml 지정User-agent: *Allow: /Sitemap: http://www.example.com/sitemap.xml 다음 로봇 규약 설정 모든 로봇의 접근 차단User-agent: *Disallow: / 카카오 로봇 규약 설정 모든 로봇의 접근 차단 See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file To ban all spiders from the entire site uncomment the next two lines:User-agent: *Disallow: / 문제가 있거나 오타가 있으면 댓글이나 메일로 알려주세요.감사합니다 :) 자세한 내용은 아래 사이트를 참조하세요.출처: https://gbsb.tistory.com/80출처: https://medium.com/@euncho/robots-txt-e08328c4f0fd출처: https://support.google.com/webmasters/answer/6062596?hl=ko출처: https://ko.wikipedia.org/wiki/%EB%A1%9C%EB%B4%87_%EB%B0%B0%EC%A0%9C_%ED%91%9C%EC%A4%80","link":"/2020/04/21/webcrawling-robots.txt/"},{"title":"webcrawling","text":"※ 출처 : fast campus 머신러닝 인강(변영효 강사님) 일부 내용만 발췌하였고, 기본적인 개념 및 추가내용을 확인하시려면 인강 수강을 권장드립니다. 내용요약 웹사이트에서 원하는 정보의 태그를 파악 모듈을 통해 태그를 찾은 후 원하는 값을 가져옴 2. HTML(Hyper Text Markup Language) 웹 사이트를 생성하기 위한 언어로 문서와 문서가 링크로 연결되어 있고, 태그를 사용하는 언어 태그 : HTML 문서의 기본 블락 브라우저에 어떻게 렌더링(화면에 표시)될지 전달 &lt;태그명 속성1=”속성값1” 속성2=”속성값2”&gt;Value&lt;/태그명&gt; &lt;태그명 속성1=”속성값1” 속성2=”속성값2”/&gt; p 태그 : paragraph tag 한 문단으로 표시해주는 태그 div 태그 그룹핑을 하는 태그 대부분의 crawling은 태그 안에 있는 값을 추출하는 작업입니다. html 기본구조 BeautifulSoup test Contents Title Test contents Test Test Test 1 Test Test Test 2 Test Test Test 3 웹 사이트에서 본인에게 필요한 정보를 가져오는 실습을 해보는걸 추천드립니다.","link":"/2020/04/21/webcrawling-2/"}],"tags":[{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"create","slug":"create","link":"/tags/create/"},{"name":"concept","slug":"concept","link":"/tags/concept/"},{"name":"eda","slug":"eda","link":"/tags/eda/"},{"name":"EDA","slug":"EDA","link":"/tags/EDA/"},{"name":"agile","slug":"agile","link":"/tags/agile/"},{"name":"Agile","slug":"Agile","link":"/tags/Agile/"},{"name":"블로그","slug":"블로그","link":"/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/"},{"name":"next","slug":"next","link":"/tags/next/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"github.io","slug":"github-io","link":"/tags/github-io/"},{"name":"theme","slug":"theme","link":"/tags/theme/"},{"name":"STAR기법","slug":"STAR기법","link":"/tags/STAR%EA%B8%B0%EB%B2%95/"},{"name":"자기소개","slug":"자기소개","link":"/tags/%EC%9E%90%EA%B8%B0%EC%86%8C%EA%B0%9C/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"pandas","slug":"pandas","link":"/tags/pandas/"},{"name":"coding","slug":"coding","link":"/tags/coding/"},{"name":"data science","slug":"data-science","link":"/tags/data-science/"},{"name":"Machine Learnig","slug":"Machine-Learnig","link":"/tags/Machine-Learnig/"},{"name":"machine learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"머신러닝","slug":"머신러닝","link":"/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"ml","slug":"ml","link":"/tags/ml/"},{"name":"linear regression","slug":"linear-regression","link":"/tags/linear-regression/"},{"name":"선형회귀분석","slug":"선형회귀분석","link":"/tags/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/"},{"name":"anova","slug":"anova","link":"/tags/anova/"},{"name":"cv","slug":"cv","link":"/tags/cv/"},{"name":"cross validation","slug":"cross-validation","link":"/tags/cross-validation/"},{"name":"favicon","slug":"favicon","link":"/tags/favicon/"},{"name":"data analysis","slug":"data-analysis","link":"/tags/data-analysis/"},{"name":"big data","slug":"big-data","link":"/tags/big-data/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"spark","slug":"spark","link":"/tags/spark/"},{"name":"hadoop","slug":"hadoop","link":"/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","link":"/tags/hdfs/"},{"name":"project","slug":"project","link":"/tags/project/"},{"name":"re","slug":"re","link":"/tags/re/"},{"name":"programming","slug":"programming","link":"/tags/programming/"},{"name":"terminal command","slug":"terminal-command","link":"/tags/terminal-command/"},{"name":"terminal","slug":"terminal","link":"/tags/terminal/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"iTerm","slug":"iTerm","link":"/tags/iTerm/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"test","slug":"test","link":"/tags/test/"},{"name":"sql","slug":"sql","link":"/tags/sql/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"visit","slug":"visit","link":"/tags/visit/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"webcrawling","slug":"webcrawling","link":"/tags/webcrawling/"},{"name":"get","slug":"get","link":"/tags/get/"},{"name":"post","slug":"post","link":"/tags/post/"},{"name":"randering","slug":"randering","link":"/tags/randering/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"robots.txt","slug":"robots-txt","link":"/tags/robots-txt/"}],"categories":[{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"concept","slug":"concept","link":"/categories/concept/"},{"name":"post","slug":"hexo/post","link":"/categories/hexo/post/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"EDA","slug":"concept/EDA","link":"/categories/concept/EDA/"},{"name":"ML","slug":"ML","link":"/categories/ML/"},{"name":"project","slug":"project","link":"/categories/project/"},{"name":"agile","slug":"concept/agile","link":"/categories/concept/agile/"},{"name":"math","slug":"math","link":"/categories/math/"},{"name":"favicon","slug":"favicon","link":"/categories/favicon/"},{"name":"Data Sciences","slug":"Data-Sciences","link":"/categories/Data-Sciences/"},{"name":"star","slug":"concept/star","link":"/categories/concept/star/"},{"name":"concept","slug":"ML/concept","link":"/categories/ML/concept/"},{"name":"linear regression","slug":"math/linear-regression","link":"/categories/math/linear-regression/"},{"name":"Data Analysis","slug":"Data-Sciences/Data-Analysis","link":"/categories/Data-Sciences/Data-Analysis/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"spark","slug":"spark","link":"/categories/spark/"},{"name":"EDA","slug":"project/EDA","link":"/categories/project/EDA/"},{"name":"concept","slug":"spark/concept","link":"/categories/spark/concept/"},{"name":"re","slug":"python/re","link":"/categories/python/re/"},{"name":"markdown","slug":"python/markdown","link":"/categories/python/markdown/"},{"name":"terminal","slug":"terminal","link":"/categories/terminal/"},{"name":"crawling","slug":"crawling","link":"/categories/crawling/"},{"name":"sql","slug":"spark/sql","link":"/categories/spark/sql/"},{"name":"command","slug":"terminal/command","link":"/categories/terminal/command/"},{"name":"concept","slug":"crawling/concept","link":"/categories/crawling/concept/"},{"name":"python","slug":"crawling/python","link":"/categories/crawling/python/"}]}